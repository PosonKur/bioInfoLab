{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_builder import create_dnn_model, create_cnn_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from model_builder import SimpleDNN, SimpleCNN\n",
    "import torch.nn.functional as F\n",
    "from plotter import visualize_tissue_image_with_samples, visualize_tissue_image_with_samples_color_labels\n",
    "\n",
    "input_csv = \"patches_with_majority_pathology.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "\n",
    "# Settings: \n",
    "do_pca = True\n",
    "pca_components = 10\n",
    "pca_dimensions = [0.8, 0.85, 0.9, 0.95]\n",
    "epochs = 1\n",
    "output_base_path = \"models/\"\n",
    "output_path_extra_desciptor = \"\" # leave empyt if not needed; \n",
    "ebbeding_dim = 1536"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b436ded",
   "metadata": {},
   "source": [
    "Get pathology training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39460e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "feature_cols = [str(i) for i in range(1536)]\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = LabelEncoder().fit_transform(df['label'].values).astype(np.int64)\n",
    "labelEncoder = LabelEncoder().fit(df['label'].values)\n",
    "\n",
    "#without pca\n",
    "dnn_output_path = \"models/dnn_pathology_model.pth\"\n",
    "df = pd.read_csv(input_csv)\n",
    "X_pcaList = []\n",
    "for d in pca_dimensions:\n",
    "# Initialize PCA with the specified number of components\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    X_pcaList.append(pca.fit_transform(X))\n",
    "    \n",
    "\n",
    "# The new data X_pca has reduced dimensions\n",
    "#print(f\"Original data shape: {X.shape}\")\n",
    "# print(f\"Data shape after PCA: {X_pca.shape}\")\n",
    "\n",
    "# # You can also see how much variance is explained by each component\n",
    "# print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "# print(f\"Total variance explained by {pca_components} components: {np.sum(pca.explained_variance_ratio_):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b11fbc",
   "metadata": {},
   "source": [
    "Train DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ae8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_list = []\n",
    "acc_list = []\n",
    "if do_pca:\n",
    "    print(\"Using PCA for dimensionality reduction...\")\n",
    "    for i, X_pca in enumerate(X_pcaList):\n",
    "        print(f\"Shape of PCA transformed data: {X_pca.shape}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        dnn_output_path = f\"{output_base_path}/dnn_pathology_model_pca_{pca_components}.pth\"\n",
    "        model,acc = create_dnn_model(X_train, X_test, y_train, y_test, dnn_output_path, labelEncoder, inputDim=pca_components, epochs=epochs)\n",
    "        dnn_list.append(model)\n",
    "        acc_list.append(acc)\n",
    "        print(f\"Training set size: {X_train.shape[0]}\")\n",
    "        print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "        print(\"\")\n",
    "# Once without PCA        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "dnn_output_path = f\"{output_base_path}/dnn_pathology_model_without_pca.pth\"\n",
    "dnn_without_pca, acc_without_pca = create_dnn_model(X_train, X_test, y_train, y_test, dnn_output_path, labelEncoder, inputDim=ebbeding_dim, epochs=epochs)\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504dd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "000164a5",
   "metadata": {},
   "source": [
    "Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ca9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_output_path = \"models/cnn_pathology_model.pth\" # not needed anymore since we dont save the models externally\n",
    "create_cnn_model(X_train, X_test, y_train, y_test, cnn_output_path, labelEncoder,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd9c00",
   "metadata": {},
   "source": [
    "~~Load trained models and perform dummy predictions~~ We dont extrnaly save the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f26ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load DNN model\n",
    "# if do_pca:\n",
    "#     input_dim = pca_components\n",
    "# else:\n",
    "#     input_dim = 1536\n",
    "# dnn_list = []\n",
    "\n",
    "# #for each pca_components in pca_dimensions load all models\n",
    "# for pca_components in pca_dimensions:\n",
    "#     dnn_output_path = f\"{output_base_path}dnn_pathology_model_pca_{pca_components}.pth\"\n",
    "#     dnn_model = SimpleDNN(input_dim, len(np.unique(y_train)))\n",
    "#     checkpoint_dnn = torch.load(dnn_output_path)\n",
    "#     dnn_model.load_state_dict(checkpoint_dnn.get(\"state_dict\", checkpoint_dnn))\n",
    "#     dnn_list.append(dnn_model)\n",
    "#     dnn_model.eval()\n",
    "\n",
    "\n",
    "    \n",
    "# # dnn_model = SimpleDNN(input_dim, len(np.unique(y_train)))\n",
    "# # checkpoint_dnn = torch.load(dnn_output_path)\n",
    "# # dnn_model.load_state_dict(checkpoint_dnn.get(\"state_dict\", checkpoint_dnn))\n",
    "# # dnn_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b30448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load CNN model\n",
    "# cnn_model = SimpleCNN(len(np.unique(y_train)))\n",
    "# checkpoint_cnn = torch.load(cnn_output_path)\n",
    "# cnn_model.load_state_dict(checkpoint_cnn.get(\"state_dict\", checkpoint_cnn))\n",
    "# cnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load saved label classes from the DNN model checkpoint\n",
    "# checkpoint = torch.load(dnn_output_path)\n",
    "# if \"label_classes\" in checkpoint:\n",
    "#     original_labels = np.array(checkpoint[\"label_classes\"])\n",
    "\n",
    "# # One sample demo predictions of DNN model\n",
    "# sample_input = torch.tensor(X_test[0]).unsqueeze(0)  # Add batch dimension\n",
    "# dnn_output = dnn_model(sample_input)\n",
    "# dnn_pred_enc = F.softmax(dnn_output, dim=1).argmax(dim=1).item()\n",
    "# dnn_pred_label = original_labels[dnn_pred_enc]\n",
    "# true_label = original_labels[y_test[0]]\n",
    "# print(f\"DNN model prediction: {dnn_pred_label} (encoded: {dnn_pred_enc}), True: {true_label} (encoded: {y_test[0]})\")\n",
    "\n",
    "# # One sample demo predictions of CNN model\n",
    "# sample_input = torch.tensor(X_test[0]).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "# #cnn_output = cnn_model(sample_input)\n",
    "# #cnn_pred_enc = F.softmax(cnn_output, dim=1).argmax(dim=1).item()\n",
    "# #cnn_pred_label = original_labels[cnn_pred_enc]\n",
    "# #print(f\"CNN model prediction: {cnn_pred_label} (encoded: {cnn_pred_enc}), True: {true_label} (encoded: {y_test[0]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57471c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e16a32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd062c08",
   "metadata": {},
   "source": [
    "## Visualize Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"spatial/tissue_hires_image.png\"\n",
    "visualize_tissue_image_with_samples(image_path, df, 27482, 25219)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22a113",
   "metadata": {},
   "source": [
    "## Visualize Ground Truth Labels on Tissue Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d28bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"spatial/tissue_hires_image.png\"\n",
    "visualize_tissue_image_with_samples_color_labels(image_path, df, 27482, 25219)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad84cb9",
   "metadata": {},
   "source": [
    "## Visualize predictions from DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = labelEncoder.classes_.tolist()\n",
    "\n",
    "# Get predictions for all data\n",
    "list_of_prediced_labels = []\n",
    "X_tensor = torch.tensor(X_pca).float()\n",
    "list_of_df_predicted_dnn = []\n",
    "for i,dnn_model in enumerate(dnn_list):\n",
    "    # for each dnn_model in dnn_list ceate a df with Patch X and Patch Y as columns and then a predicted label column\n",
    "    X_tensor = torch.tensor(X_pcaList[i]).float()\n",
    "    with torch.no_grad():\n",
    "        dnn_outputs_temp = dnn_model(X_tensor)\n",
    "        temp = F.softmax(dnn_outputs_temp, dim=1).argmax(dim=1)\n",
    "        # list comphehension of predicted labels\n",
    "        prediced_labels =  [original_labels[label] for label in temp.numpy()]\n",
    "        df_predicted_dnn = df[['Patch_X', 'Patch_Y']].copy()\n",
    "        df_predicted_dnn['label'] = prediced_labels\n",
    "        list_of_prediced_labels.append(prediced_labels)\n",
    "        # Append the dataframe to the list\n",
    "        df_predicted_dnn['model'] = f'dnn_pca_{i+1}'\n",
    "        df_predicted_dnn['pca_components'] = pca_components\n",
    "        list_of_df_predicted_dnn.append(df_predicted_dnn)\n",
    "        # Append the dataframe to the list\n",
    "# Decode predictions\n",
    "# Visualize the results from the first models\n",
    "for i, df_predicted_dnn in enumerate(list_of_df_predicted_dnn):\n",
    "    visualize_tissue_image_with_samples_color_labels(image_path,list_of_df_predicted_dnn[0], 27482, 25219)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#visualioze tissue image for first \n",
    "#zxxx = list_of_df_predicted_dnn[0]\n",
    "# # Create the new dataframe\n",
    "\n",
    "#print(df_predicted_dnn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11aad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_df_predicted_dnn[0]['label'])  # Print first 10 predicted labels for the first model\n",
    "image_path = \"spatial/tissue_hires_image.png\"\n",
    "visualize_tissue_image_with_samples_color_labels(image_path,list_of_df_predicted_dnn[0], 27482, 25219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260bb3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfolab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
