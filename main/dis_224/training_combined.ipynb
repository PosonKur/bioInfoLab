{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4de5229",
   "metadata": {},
   "source": [
    "# Combined Training Notebook\n",
    "\n",
    "This notebook combines the functionality from main.ipynb and train_with_conf.ipynb to run both training approaches sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb3aa5",
   "metadata": {},
   "source": [
    "# Part 1: Main Training Pipeline (from main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_builder import create_dnn_model, create_cnn_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from model_builder import SimpleDNN, SimpleCNN\n",
    "import torch.nn.functional as F\n",
    "from plotter import visualize_tissue_image_with_samples, visualize_tissue_image_with_samples_color_labels\n",
    "\n",
    "input_csv = \"training_data/WSI_patch_embeddings_centered-224_adenocarcinoma_leiden_0.3_training-data.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Settings: \n",
    "do_pca = True\n",
    "\n",
    "# Using variance explained percentages instead of fixed component numbers\n",
    "pca_dimensions = [0.80, 0.85, 0.90, 0.95]  # 80%, 85%, 90%, 95% variance explained\n",
    "\n",
    "# Legacy setting (not used anymore when do_pca=True)\n",
    "pca_components = 10  # This is now ignored when using variance-based PCA\n",
    "\n",
    "epochs = 30\n",
    "output_base_path = \"models/\"\n",
    "output_path_extra_desciptor = \"\" # leave empty if not needed; \n",
    "ebbeding_dim = 1536\n",
    "result_subfolder = \"leiden_0.3_adenocarcinoma_224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc0e72",
   "metadata": {},
   "source": [
    "Get pathology training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_cols = [str(i) for i in range(1536)]\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X).astype(np.float32)\n",
    "y = LabelEncoder().fit_transform(df['label'].values).astype(np.int64)\n",
    "labelEncoder = LabelEncoder().fit(df['label'].values)\n",
    "\n",
    "# Create train/validation/test splits (60/20/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "X_pcaList = []\n",
    "X_val_pcaList = []\n",
    "X_test_pcaList = []\n",
    "\n",
    "# Using variance explained (0.80 = 80% variance, etc.)\n",
    "variance_explained_ratios = [0.80, 0.85, 0.90, 0.95]\n",
    "pca_component_numbers = []  # Will store actual component numbers for each variance ratio\n",
    "\n",
    "print(f\"Using PCA with variance explained ratios: {[f'{v*100}%' for v in variance_explained_ratios]}\")\n",
    "\n",
    "for variance_explained in variance_explained_ratios:\n",
    "    pca = PCA(n_components=variance_explained)  # This will automatically determine n_components\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    actual_components = pca.n_components_\n",
    "    actual_variance = pca.explained_variance_ratio_.sum()\n",
    "    pca_component_numbers.append(actual_components)\n",
    "    \n",
    "    print(f\"PCA with {variance_explained*100}% variance target uses {actual_components} components\")\n",
    "    print(f\"Actual variance explained: {actual_variance:.3f} ({actual_variance*100:.1f}%)\")\n",
    "    print(f\"Shape: {X_train_pca.shape}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    X_pcaList.append(X_train_pca)\n",
    "    X_val_pcaList.append(X_val_pca)\n",
    "    X_test_pcaList.append(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bfe659",
   "metadata": {},
   "source": [
    "Train DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b16444",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_list = []\n",
    "acc_list_dnn = []\n",
    "if do_pca:\n",
    "    print(\"Using PCA for dimensionality reduction...\")\n",
    "    for i, X_train_pca in enumerate(X_pcaList):\n",
    "        current_components = X_train_pca.shape[1]  # Get actual number of components\n",
    "        print(f\"Shape of PCA transformed data: {X_train_pca.shape}\")\n",
    "        \n",
    "        dnn_output_path = f\"{output_base_path}/dnn_pathology_model_pca_{current_components}.pth\"\n",
    "        model, acc = create_dnn_model(X_train_pca, X_val_pcaList[i], y_train, y_val, dnn_output_path, labelEncoder, \n",
    "                                   inputDim=current_components, epochs=epochs)\n",
    "        dnn_list.append(model)\n",
    "        acc_list_dnn.append(acc)\n",
    "        print(f\"Training set size: {X_train_pca.shape[0]}\")\n",
    "        print(f\"Validation set size: {X_val_pcaList[i].shape[0]}\")\n",
    "        print(\"\")\n",
    "        \n",
    "# Once without PCA        \n",
    "dnn_output_path = f\"{output_base_path}/dnn_pathology_model_without_pca.pth\"\n",
    "dnn_without_pca, acc_without_pca = create_dnn_model(X_train, X_val, y_train, y_val, dnn_output_path, labelEncoder, \n",
    "                                                  inputDim=ebbeding_dim, epochs=epochs)\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate DNN models on validation set\n",
    "from sklearn.metrics import adjusted_rand_score, f1_score, accuracy_score\n",
    "\n",
    "# Get predictions for validation data\n",
    "original_labels = labelEncoder.classes_.tolist()\n",
    "list_of_prediced_labels_dnn = []\n",
    "ari_score_list_dnn = []\n",
    "f1_score_list_dnn = []\n",
    "accuracy_list_dnn = []\n",
    "\n",
    "for i, dnn_model in enumerate(dnn_list):\n",
    "    # Get validation predictions for each dnn_model\n",
    "    X_val_tensor = torch.tensor(X_val_pcaList[i]).float()\n",
    "    with torch.no_grad():\n",
    "        dnn_outputs_temp = dnn_model(X_val_tensor)\n",
    "        temp = F.softmax(dnn_outputs_temp, dim=1).argmax(dim=1)\n",
    "        # list comprehension of predicted labels\n",
    "        prediced_labels = [original_labels[label] for label in temp.numpy()]\n",
    "        list_of_prediced_labels_dnn.append(prediced_labels)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    ari_score = adjusted_rand_score(y_val, prediced_labels)\n",
    "    f1_score_val = f1_score(y_val, prediced_labels, average='weighted')\n",
    "    accuracy_val = accuracy_score(y_val, prediced_labels)\n",
    "    \n",
    "    ari_score_list_dnn.append(ari_score)\n",
    "    f1_score_list_dnn.append(f1_score_val)\n",
    "    accuracy_list_dnn.append(accuracy_val)\n",
    "    \n",
    "    print(f\"DNN PCA {i+1} - Validation Accuracy: {accuracy_val:.3f}, ARI: {ari_score:.3f}, F1: {f1_score_val:.3f}\")\n",
    "\n",
    "# Evaluate DNN without PCA on validation set\n",
    "X_val_tensor = torch.tensor(X_val).float()\n",
    "with torch.no_grad():\n",
    "    dnn_outputs = dnn_without_pca(X_val_tensor)\n",
    "    dnn_preds_enc = F.softmax(dnn_outputs, dim=1).argmax(dim=1)\n",
    "predicted_labels_dnn_no_pca = [original_labels[label] for label in dnn_preds_enc.numpy()]\n",
    "\n",
    "# Calculate validation metrics for DNN without PCA\n",
    "ari_dnn_no_pca = adjusted_rand_score(y_val, predicted_labels_dnn_no_pca)\n",
    "f1_dnn_no_pca = f1_score(y_val, predicted_labels_dnn_no_pca, average='weighted')\n",
    "accuracy_dnn_no_pca = accuracy_score(y_val, predicted_labels_dnn_no_pca)\n",
    "\n",
    "print(f\"DNN without PCA - Validation Accuracy: {accuracy_dnn_no_pca:.3f}, ARI: {ari_dnn_no_pca:.3f}, F1: {f1_dnn_no_pca:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad973d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8db3fdd8",
   "metadata": {},
   "source": [
    "Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_list = []\n",
    "acc_list_cnn = []\n",
    "if do_pca:\n",
    "    print(\"Using PCA for dimensionality reduction...\")\n",
    "    for i, X_train_pca in enumerate(X_pcaList):\n",
    "        current_components = X_train_pca.shape[1]  # Get actual number of components\n",
    "        print(f\"Shape of PCA transformed data: {X_train_pca.shape}\")\n",
    "        \n",
    "        cnn_output_path = f\"{output_base_path}/cnn_pathology_model_pca_{current_components}.pth\"\n",
    "        model, acc = create_cnn_model(X_train_pca, X_val_pcaList[i], y_train, y_val, cnn_output_path, labelEncoder, \n",
    "                                   inputDim=current_components, epochs=epochs)\n",
    "        cnn_list.append(model)\n",
    "        acc_list_cnn.append(acc)\n",
    "        print(f\"CNN PCA {i+1} training accuracy: {acc:.3f}\")\n",
    "        print(f\"Training set size: {X_train_pca.shape[0]}\")\n",
    "        print(f\"Validation set size: {X_val_pcaList[i].shape[0]}\")\n",
    "        print(\"\")\n",
    "        \n",
    "# Once without PCA        \n",
    "cnn_output_path = f\"{output_base_path}/cnn_pathology_model_without_pca.pth\"\n",
    "cnn_without_pca, acc_without_pca_cnn = create_cnn_model(X_train, X_val, y_train, y_val, cnn_output_path, labelEncoder, \n",
    "                                                      inputDim=ebbeding_dim, epochs=epochs)\n",
    "print(f\"CNN without PCA training accuracy: {acc_without_pca_cnn:.3f}\")\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c9ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CNN models on validation set\n",
    "list_of_prediced_labels_cnn = []\n",
    "ari_score_list_cnn = []\n",
    "f1_score_list_cnn = []\n",
    "accuracy_list_cnn = []\n",
    "\n",
    "for i, cnn_model in enumerate(cnn_list):\n",
    "    # Get validation predictions for each cnn_model\n",
    "    X_val_tensor = torch.tensor(X_val_pcaList[i]).float()\n",
    "    with torch.no_grad():\n",
    "        cnn_outputs_temp = cnn_model(X_val_tensor.unsqueeze(1))  # Add channel dimension for CNN\n",
    "        temp = F.softmax(cnn_outputs_temp, dim=1).argmax(dim=1)\n",
    "        # list comprehension of predicted labels\n",
    "        prediced_labels = [original_labels[label] for label in temp.numpy()]\n",
    "        list_of_prediced_labels_cnn.append(prediced_labels)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    ari_score = adjusted_rand_score(y_val, prediced_labels)\n",
    "    f1_score_val = f1_score(y_val, prediced_labels, average='weighted')\n",
    "    accuracy_val = accuracy_score(y_val, prediced_labels)\n",
    "    \n",
    "    ari_score_list_cnn.append(ari_score)\n",
    "    f1_score_list_cnn.append(f1_score_val)\n",
    "    accuracy_list_cnn.append(accuracy_val)\n",
    "    \n",
    "    print(f\"CNN PCA {i+1} - Validation Accuracy: {accuracy_val:.3f}, ARI: {ari_score:.3f}, F1: {f1_score_val:.3f}\")\n",
    "\n",
    "# Evaluate CNN without PCA on validation set\n",
    "X_val_tensor = torch.tensor(X_val).float()\n",
    "with torch.no_grad():\n",
    "    cnn_outputs = cnn_without_pca(X_val_tensor.unsqueeze(1))  # Add channel dimension\n",
    "    cnn_preds_enc = F.softmax(cnn_outputs, dim=1).argmax(dim=1)\n",
    "predicted_labels_cnn_no_pca = [original_labels[label] for label in cnn_preds_enc.numpy()]\n",
    "\n",
    "# Calculate validation metrics for CNN without PCA\n",
    "ari_cnn_no_pca = adjusted_rand_score(y_val, predicted_labels_cnn_no_pca)\n",
    "f1_cnn_no_pca = f1_score(y_val, predicted_labels_cnn_no_pca, average='weighted')\n",
    "accuracy_cnn_no_pca = accuracy_score(y_val, predicted_labels_cnn_no_pca)\n",
    "\n",
    "print(f\"CNN without PCA - Validation Accuracy: {accuracy_cnn_no_pca:.3f}, ARI: {ari_cnn_no_pca:.3f}, F1: {f1_cnn_no_pca:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30fc02",
   "metadata": {},
   "source": [
    "## Main Pipeline Validation Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation results summary for main pipeline\n",
    "print(\"=== MAIN PIPELINE VALIDATION RESULTS SUMMARY ===\")\n",
    "\n",
    "# Compile all main pipeline validation results\n",
    "main_validation_results = []\n",
    "\n",
    "# Add DNN results with PCA\n",
    "for i in range(len(dnn_list)):\n",
    "    main_validation_results.append({\n",
    "        'model': f'dnn_pca_{i+1}',\n",
    "        'architecture': 'DNN',\n",
    "        'pca_components': pca_component_numbers[i],\n",
    "        'training_accuracy': acc_list_dnn[i],  # From training\n",
    "        'validation_accuracy': accuracy_list_dnn[i],  # From validation\n",
    "        'validation_ari': ari_score_list_dnn[i],\n",
    "        'validation_f1': f1_score_list_dnn[i]\n",
    "    })\n",
    "\n",
    "# Add DNN without PCA\n",
    "main_validation_results.append({\n",
    "    'model': 'dnn_without_pca',\n",
    "    'architecture': 'DNN',\n",
    "    'pca_components': 'None',\n",
    "    'training_accuracy': acc_without_pca,  # From training\n",
    "    'validation_accuracy': accuracy_dnn_no_pca,  # From validation\n",
    "    'validation_ari': ari_dnn_no_pca,\n",
    "    'validation_f1': f1_dnn_no_pca\n",
    "})\n",
    "\n",
    "# Add CNN results with PCA\n",
    "for i in range(len(cnn_list)):\n",
    "    main_validation_results.append({\n",
    "        'model': f'cnn_pca_{i+1}',\n",
    "        'architecture': 'CNN',\n",
    "        'pca_components': pca_component_numbers[i],\n",
    "        'training_accuracy': acc_list_cnn[i],  # From training\n",
    "        'validation_accuracy': accuracy_list_cnn[i],  # From validation\n",
    "        'validation_ari': ari_score_list_cnn[i],\n",
    "        'validation_f1': f1_score_list_cnn[i]\n",
    "    })\n",
    "\n",
    "# Add CNN without PCA\n",
    "main_validation_results.append({\n",
    "    'model': 'cnn_without_pca',\n",
    "    'architecture': 'CNN',\n",
    "    'pca_components': 'None',\n",
    "    'training_accuracy': acc_without_pca_cnn,  # From CNN training\n",
    "    'validation_accuracy': accuracy_cnn_no_pca,  # From validation\n",
    "    'validation_ari': ari_cnn_no_pca,\n",
    "    'validation_f1': f1_cnn_no_pca\n",
    "})\n",
    "\n",
    "# Create DataFrame and save results\n",
    "main_validation_results_df = pd.DataFrame(main_validation_results)\n",
    "main_validation_csv_path = f\"results/{result_subfolder}/main_pipeline_validation_results.csv\"\n",
    "\n",
    "# Create results directory\n",
    "import os\n",
    "results_dir = f\"results/{result_subfolder}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "main_validation_results_df.to_csv(main_validation_csv_path, index=False)\n",
    "\n",
    "print(f\"Main pipeline validation results saved to: {main_validation_csv_path}\")\n",
    "print(\"\\nMain Pipeline Validation Results Summary:\")\n",
    "print(main_validation_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fac59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa70778",
   "metadata": {},
   "source": [
    "## Visualize Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e689df",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"spatial/tissue_hires_image.png\"\n",
    "visualize_tissue_image_with_samples(image_path, df, 27482, 25219)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c61638",
   "metadata": {},
   "source": [
    "# Final Test Set Evaluation\n",
    "\n",
    "Now that we've developed and tuned our models using the validation set, we can perform final evaluation on the test set. This gives us an unbiased estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set for DNN models\n",
    "print(\"=== FINAL TEST SET EVALUATION - DNN MODELS ===\")\n",
    "\n",
    "# Get original labels\n",
    "original_labels = labelEncoder.classes_.tolist()\n",
    "\n",
    "# Evaluate DNN models with PCA on test set\n",
    "test_results_dnn = []\n",
    "for i, dnn_model in enumerate(dnn_list):\n",
    "    X_test_tensor = torch.tensor(X_test_pcaList[i]).float()\n",
    "    with torch.no_grad():\n",
    "        dnn_outputs = dnn_model(X_test_tensor)\n",
    "        dnn_preds_enc = F.softmax(dnn_outputs, dim=1).argmax(dim=1)\n",
    "    \n",
    "    predicted_labels = [original_labels[label] for label in dnn_preds_enc.numpy()]\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    from sklearn.metrics import adjusted_rand_score, f1_score\n",
    "    test_ari = adjusted_rand_score(y_test, predicted_labels)\n",
    "    test_f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Calculate test accuracy manually\n",
    "    correct = (dnn_preds_enc.numpy() == y_test).sum()\n",
    "    test_accuracy = correct / len(y_test)\n",
    "    \n",
    "    test_results_dnn.append({\n",
    "        'model': f'dnn_pca_{i+1}',\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_ari': test_ari,\n",
    "        'test_f1': test_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"DNN PCA {i+1} - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")\n",
    "\n",
    "# Evaluate DNN without PCA on test set\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "with torch.no_grad():\n",
    "    dnn_outputs = dnn_without_pca(X_test_tensor)\n",
    "    dnn_preds_enc = F.softmax(dnn_outputs, dim=1).argmax(dim=1)\n",
    "\n",
    "predicted_labels = [original_labels[label] for label in dnn_preds_enc.numpy()]\n",
    "test_ari = adjusted_rand_score(y_test, predicted_labels)\n",
    "test_f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "correct = (dnn_preds_enc.numpy() == y_test).sum()\n",
    "test_accuracy = correct / len(y_test)\n",
    "\n",
    "test_results_dnn.append({\n",
    "    'model': 'dnn_without_pca',\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_ari': test_ari,\n",
    "    'test_f1': test_f1\n",
    "})\n",
    "\n",
    "print(f\"DNN without PCA - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbd123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set for CNN models\n",
    "print(\"\\n=== FINAL TEST SET EVALUATION - CNN MODELS ===\")\n",
    "\n",
    "# Evaluate CNN models with PCA on test set\n",
    "test_results_cnn = []\n",
    "for i, cnn_model in enumerate(cnn_list):\n",
    "    X_test_tensor = torch.tensor(X_test_pcaList[i]).float()\n",
    "    with torch.no_grad():\n",
    "        cnn_outputs = cnn_model(X_test_tensor.unsqueeze(1))  # Add channel dimension for CNN\n",
    "        cnn_preds_enc = F.softmax(cnn_outputs, dim=1).argmax(dim=1)\n",
    "    \n",
    "    predicted_labels = [original_labels[label] for label in cnn_preds_enc.numpy()]\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_ari = adjusted_rand_score(y_test, predicted_labels)\n",
    "    test_f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Calculate test accuracy manually\n",
    "    correct = (cnn_preds_enc.numpy() == y_test).sum()\n",
    "    test_accuracy = correct / len(y_test)\n",
    "    \n",
    "    test_results_cnn.append({\n",
    "        'model': f'cnn_pca_{i+1}',\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_ari': test_ari,\n",
    "        'test_f1': test_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"CNN PCA {i+1} - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")\n",
    "\n",
    "# Evaluate CNN without PCA on test set\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "with torch.no_grad():\n",
    "    cnn_outputs = cnn_without_pca(X_test_tensor.unsqueeze(1))  # Add channel dimension\n",
    "    cnn_preds_enc = F.softmax(cnn_outputs, dim=1).argmax(dim=1)\n",
    "\n",
    "predicted_labels = [original_labels[label] for label in cnn_preds_enc.numpy()]\n",
    "test_ari = adjusted_rand_score(y_test, predicted_labels)\n",
    "test_f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "correct = (cnn_preds_enc.numpy() == y_test).sum()\n",
    "test_accuracy = correct / len(y_test)\n",
    "\n",
    "test_results_cnn.append({\n",
    "    'model': 'cnn_without_pca',\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_ari': test_ari,\n",
    "    'test_f1': test_f1\n",
    "})\n",
    "\n",
    "print(f\"CNN without PCA - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")\n",
    "\n",
    "# Save combined test results\n",
    "print(\"\\n=== SAVING FINAL TEST RESULTS ===\")\n",
    "\n",
    "# Combine all test results\n",
    "all_test_results = test_results_dnn + test_results_cnn\n",
    "\n",
    "# Save to CSV\n",
    "test_results_df = pd.DataFrame(all_test_results)\n",
    "test_csv_path = f\"results/{result_subfolder}/final_test_scores.csv\"\n",
    "test_results_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "print(f\"Final test results saved to: {test_csv_path}\")\n",
    "print(\"\\nFinal Test Results Summary:\")\n",
    "print(test_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4cc87",
   "metadata": {},
   "source": [
    "# Part 2: Confidence-based Training Pipeline (from train_with_conf.ipynb)\n",
    "\n",
    "This section implements training with confidence-weighted samples, where each training sample has an associated confidence score indicating how certain we are about its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c914f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confidence-based model builder\n",
    "from model_builder_with_conf import create_dnn_model as create_dnn_model_conf, create_cnn_model as create_cnn_model_conf\n",
    "from model_builder_with_conf import SimpleDNN as SimpleDNN_conf, SimpleCNN as SimpleCNN_conf\n",
    "from plotter_standard import visualize_tissue_image_with_samples, visualize_tissue_image_with_samples_color_labels\n",
    "\n",
    "# Configuration for confidence-based training\n",
    "input_csv_conf = \"training_data/WSI_patch_embeddings_standard-224_adenocarcinoma_leiden_0.3_training-data.csv\"\n",
    "df_conf = pd.read_csv(input_csv_conf)\n",
    "\n",
    "# Settings for confidence-based training\n",
    "do_pca_conf = True\n",
    "pca_dimensions_conf = [0.8, 0.85, 0.9, 0.95]  # Different format from main pipeline\n",
    "epochs_conf = 30\n",
    "output_base_path_conf = \"models/conf_weighted/\"\n",
    "ebbeding_dim_conf = 1536\n",
    "result_subfolder_conf = \"leiden_0.3_adenocarcinoma_224_confidence\"\n",
    "\n",
    "print(f\"Confidence-based dataset shape: {df_conf.shape}\")\n",
    "print(f\"Columns in confidence dataset: {df_conf.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fd73f",
   "metadata": {},
   "source": [
    "## Prepare Confidence-based Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels for confidence-based training\n",
    "feature_cols_conf = [str(i) for i in range(1536)]\n",
    "X_conf = df_conf[feature_cols_conf].values.astype(np.float32)\n",
    "\n",
    "# Standardize features\n",
    "scaler_conf = StandardScaler()\n",
    "X_conf = scaler_conf.fit_transform(X_conf).astype(np.float32)\n",
    "y_conf = LabelEncoder().fit_transform(df_conf['label'].values).astype(np.int64)\n",
    "labelEncoder_conf = LabelEncoder().fit(df_conf['label'].values)\n",
    "\n",
    "# Extract confidence scores - required column\n",
    "if 'confidence' not in df_conf.columns:\n",
    "    raise ValueError(\"Expected 'confidence' column not found in the dataset!\")\n",
    "\n",
    "confidence_scores = df_conf['confidence'].values.astype(np.float32)\n",
    "print(f\"Using confidence scores. Range: {confidence_scores.min():.3f} - {confidence_scores.max():.3f}\")\n",
    "print(f\"Mean confidence: {confidence_scores.mean():.3f}\")\n",
    "\n",
    "# Create train/validation/test splits for confidence-based training (60/20/20 split like main pipeline)\n",
    "# We need to preserve indices to map back to original dataframe for visualization\n",
    "indices = np.arange(len(X_conf))\n",
    "X_temp_conf, X_test_conf, y_temp_conf, y_test_conf, idx_temp, idx_test = train_test_split(\n",
    "    X_conf, y_conf, indices, test_size=0.2, random_state=42, stratify=y_conf)\n",
    "X_train_conf, X_val_conf, y_train_conf, y_val_conf, idx_train, idx_val = train_test_split(\n",
    "    X_temp_conf, y_temp_conf, idx_temp, test_size=0.25, random_state=42, stratify=y_temp_conf)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Split confidence scores accordingly\n",
    "conf_temp, conf_test = train_test_split(\n",
    "    confidence_scores, test_size=0.2, random_state=42, stratify=y_conf)\n",
    "conf_train, conf_val = train_test_split(\n",
    "    conf_temp, test_size=0.25, random_state=42, stratify=y_temp_conf)\n",
    "\n",
    "print(f\"Confidence training set size: {X_train_conf.shape[0]} ({X_train_conf.shape[0]/len(X_conf)*100:.1f}%)\")\n",
    "print(f\"Confidence validation set size: {X_val_conf.shape[0]} ({X_val_conf.shape[0]/len(X_conf)*100:.1f}%)\")\n",
    "print(f\"Confidence test set size: {X_test_conf.shape[0]} ({X_test_conf.shape[0]/len(X_conf)*100:.1f}%)\")\n",
    "\n",
    "# Prepare PCA transformations for confidence-based training\n",
    "X_pcaList_conf = []\n",
    "X_val_pcaList_conf = []\n",
    "X_test_pcaList_conf = []\n",
    "\n",
    "for d in pca_dimensions_conf:\n",
    "    # Initialize PCA with the specified number of components\n",
    "    pca_conf = PCA(n_components=d)\n",
    "    X_train_pca_conf = pca_conf.fit_transform(X_train_conf)\n",
    "    X_val_pca_conf = pca_conf.transform(X_val_conf)\n",
    "    X_test_pca_conf = pca_conf.transform(X_test_conf)\n",
    "    \n",
    "    actual_variance = pca_conf.explained_variance_ratio_.sum()\n",
    "    print(f\"PCA with {d} components explains {actual_variance:.3f} ({actual_variance*100:.1f}%) variance\")\n",
    "    print(f\"Shape: {X_train_pca_conf.shape}\")\n",
    "    \n",
    "    X_pcaList_conf.append(X_train_pca_conf)\n",
    "    X_val_pcaList_conf.append(X_val_pca_conf)\n",
    "    X_test_pcaList_conf.append(X_test_pca_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe44cad",
   "metadata": {},
   "source": [
    "## Train Confidence-weighted DNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory for confidence-based models\n",
    "os.makedirs(output_base_path_conf, exist_ok=True)\n",
    "\n",
    "# Train DNN models with confidence weighting\n",
    "dnn_list_conf = []\n",
    "acc_list_conf = []\n",
    "\n",
    "if do_pca_conf:\n",
    "    print(\"Training confidence-weighted DNN models with PCA...\")\n",
    "    for i, X_train_pca_conf in enumerate(X_pcaList_conf):\n",
    "        print(f\"Shape of PCA transformed data: {X_train_pca_conf.shape}\")\n",
    "        \n",
    "        dnn_output_path_conf = f\"{output_base_path_conf}/dnn_pathology_model_pca_{X_train_pca_conf.shape[1]}.pth\"\n",
    "        model_conf, acc_conf = create_dnn_model_conf(\n",
    "            X_train_pca_conf, X_val_pcaList_conf[i], y_train_conf, y_val_conf, \n",
    "            dnn_output_path_conf, labelEncoder_conf, \n",
    "            inputDim=X_train_pca_conf.shape[1], epochs=epochs_conf, \n",
    "            train_weights=conf_train, test_weights=conf_val)\n",
    "        \n",
    "        dnn_list_conf.append(model_conf)\n",
    "        acc_list_conf.append(acc_conf)\n",
    "        print(f\"Confidence DNN PCA {i+1} training accuracy: {acc_conf:.3f}\")\n",
    "        print(f\"Training set size: {X_train_pca_conf.shape[0]}\")\n",
    "        print(f\"Validation set size: {X_val_pcaList_conf[i].shape[0]}\")\n",
    "        print(\"\")\n",
    "\n",
    "# Train DNN without PCA with confidence weighting\n",
    "dnn_output_path_conf = f\"{output_base_path_conf}/dnn_pathology_model_without_pca.pth\"\n",
    "dnn_without_pca_conf, acc_without_pca_conf = create_dnn_model_conf(\n",
    "    X_train_conf, X_val_conf, y_train_conf, y_val_conf, dnn_output_path_conf, \n",
    "    labelEncoder_conf, inputDim=ebbeding_dim_conf, epochs=epochs_conf,\n",
    "    train_weights=conf_train, test_weights=conf_val)\n",
    "\n",
    "print(f\"Confidence DNN without PCA training accuracy: {acc_without_pca_conf:.3f}\")\n",
    "print(f\"Training set size: {X_train_conf.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val_conf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddaee5d",
   "metadata": {},
   "source": [
    "## Train Confidence-weighted CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN models with confidence weighting\n",
    "cnn_list_conf = []\n",
    "acc_list_cnn_conf = []\n",
    "\n",
    "if do_pca_conf:\n",
    "    print(\"Training confidence-weighted CNN models with PCA...\")\n",
    "    for i, X_train_pca_conf in enumerate(X_pcaList_conf):\n",
    "        print(f\"Shape of PCA transformed data: {X_train_pca_conf.shape}\")\n",
    "        \n",
    "        cnn_output_path_conf = f\"{output_base_path_conf}/cnn_pathology_model_pca_{X_train_pca_conf.shape[1]}.pth\"\n",
    "        model_conf, acc_conf = create_cnn_model_conf(\n",
    "            X_train_pca_conf, X_val_pcaList_conf[i], y_train_conf, y_val_conf, \n",
    "            cnn_output_path_conf, labelEncoder_conf, \n",
    "            inputDim=X_train_pca_conf.shape[1], epochs=epochs_conf, \n",
    "            train_weights=conf_train, test_weights=conf_val)\n",
    "        \n",
    "        cnn_list_conf.append(model_conf)\n",
    "        acc_list_cnn_conf.append(acc_conf)\n",
    "        print(f\"Confidence CNN PCA {i+1} training accuracy: {acc_conf:.3f}\")\n",
    "        print(f\"Training set size: {X_train_pca_conf.shape[0]}\")\n",
    "        print(f\"Validation set size: {X_val_pcaList_conf[i].shape[0]}\")\n",
    "        print(\"\")\n",
    "\n",
    "# Train CNN without PCA with confidence weighting\n",
    "cnn_output_path_conf = f\"{output_base_path_conf}/cnn_pathology_model_without_pca.pth\"\n",
    "cnn_without_pca_conf, acc_without_pca_cnn_conf = create_cnn_model_conf(\n",
    "    X_train_conf, X_val_conf, y_train_conf, y_val_conf, cnn_output_path_conf, \n",
    "    labelEncoder_conf, inputDim=ebbeding_dim_conf, epochs=epochs_conf,\n",
    "    train_weights=conf_train, test_weights=conf_val)\n",
    "\n",
    "print(f\"Confidence CNN without PCA training accuracy: {acc_without_pca_cnn_conf:.3f}\")\n",
    "print(f\"Training set size: {X_train_conf.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val_conf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate confidence-weighted models on validation set\n",
    "print(\"=== CONFIDENCE-WEIGHTED MODEL VALIDATION EVALUATION ===\")\n",
    "\n",
    "# Get original labels from confidence model\n",
    "original_labels_conf = labelEncoder_conf.classes_.tolist()\n",
    "\n",
    "# Evaluate DNN models with confidence weighting on validation set\n",
    "list_of_predicted_labels_dnn_conf_val = []\n",
    "ari_score_list_dnn_conf_val = []\n",
    "f1_score_list_dnn_conf_val = []\n",
    "accuracy_list_dnn_conf_val = []\n",
    "\n",
    "print(\"Evaluating confidence-weighted DNN models on validation set:\")\n",
    "for i, dnn_model_conf in enumerate(dnn_list_conf):\n",
    "    # Get validation predictions for each confidence DNN model\n",
    "    X_val_tensor_conf = torch.tensor(X_val_pcaList_conf[i]).float()\n",
    "    with torch.no_grad():\n",
    "        dnn_outputs_temp = dnn_model_conf(X_val_tensor_conf)\n",
    "        temp = F.softmax(dnn_outputs_temp, dim=1).argmax(dim=1)\n",
    "        # List comprehension of predicted labels\n",
    "        predicted_labels = [original_labels_conf[label] for label in temp.numpy()]\n",
    "        list_of_predicted_labels_dnn_conf_val.append(predicted_labels)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    ari_score = adjusted_rand_score(y_val_conf, predicted_labels)\n",
    "    f1_score_val = f1_score(y_val_conf, predicted_labels, average='weighted')\n",
    "    accuracy_val = accuracy_score(y_val_conf, predicted_labels)\n",
    "    \n",
    "    ari_score_list_dnn_conf_val.append(ari_score)\n",
    "    f1_score_list_dnn_conf_val.append(f1_score_val)\n",
    "    accuracy_list_dnn_conf_val.append(accuracy_val)\n",
    "    \n",
    "    print(f\"Confidence DNN PCA {i+1} - Validation Accuracy: {accuracy_val:.3f}, ARI: {ari_score:.3f}, F1: {f1_score_val:.3f}\")\n",
    "\n",
    "# Evaluate confidence DNN without PCA on validation set\n",
    "X_val_tensor_conf = torch.tensor(X_val_conf).float()\n",
    "with torch.no_grad():\n",
    "    dnn_outputs = dnn_without_pca_conf(X_val_tensor_conf)\n",
    "    dnn_preds_enc = F.softmax(dnn_outputs, dim=1).argmax(dim=1)\n",
    "predicted_labels_dnn_no_pca_conf_val = [original_labels_conf[label] for label in dnn_preds_enc.numpy()]\n",
    "\n",
    "# Calculate validation metrics for confidence DNN without PCA\n",
    "ari_dnn_no_pca_conf_val = adjusted_rand_score(y_val_conf, predicted_labels_dnn_no_pca_conf_val)\n",
    "f1_dnn_no_pca_conf_val = f1_score(y_val_conf, predicted_labels_dnn_no_pca_conf_val, average='weighted')\n",
    "accuracy_dnn_no_pca_conf_val = accuracy_score(y_val_conf, predicted_labels_dnn_no_pca_conf_val)\n",
    "\n",
    "print(f\"Confidence DNN without PCA - Validation Accuracy: {accuracy_dnn_no_pca_conf_val:.3f}, ARI: {ari_dnn_no_pca_conf_val:.3f}, F1: {f1_dnn_no_pca_conf_val:.3f}\")\n",
    "\n",
    "# Evaluate confidence-weighted CNN models on validation set\n",
    "list_of_predicted_labels_cnn_conf_val = []\n",
    "ari_score_list_cnn_conf_val = []\n",
    "f1_score_list_cnn_conf_val = []\n",
    "accuracy_list_cnn_conf_val = []\n",
    "\n",
    "print(\"\\nEvaluating confidence-weighted CNN models on validation set:\")\n",
    "for i, cnn_model_conf in enumerate(cnn_list_conf):\n",
    "    # Get validation predictions for each confidence CNN model\n",
    "    X_val_tensor_conf = torch.tensor(X_val_pcaList_conf[i]).float()\n",
    "    with torch.no_grad():\n",
    "        cnn_outputs_temp = cnn_model_conf(X_val_tensor_conf.unsqueeze(1))  # Add channel dimension for CNN\n",
    "        temp = F.softmax(cnn_outputs_temp, dim=1).argmax(dim=1)\n",
    "        # List comprehension of predicted labels\n",
    "        predicted_labels = [original_labels_conf[label] for label in temp.numpy()]\n",
    "        list_of_predicted_labels_cnn_conf_val.append(predicted_labels)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    ari_score = adjusted_rand_score(y_val_conf, predicted_labels)\n",
    "    f1_score_val = f1_score(y_val_conf, predicted_labels, average='weighted')\n",
    "    accuracy_val = accuracy_score(y_val_conf, predicted_labels)\n",
    "    \n",
    "    ari_score_list_cnn_conf_val.append(ari_score)\n",
    "    f1_score_list_cnn_conf_val.append(f1_score_val)\n",
    "    accuracy_list_cnn_conf_val.append(accuracy_val)\n",
    "    \n",
    "    print(f\"Confidence CNN PCA {i+1} - Validation Accuracy: {accuracy_val:.3f}, ARI: {ari_score:.3f}, F1: {f1_score_val:.3f}\")\n",
    "\n",
    "# Evaluate confidence CNN without PCA on validation set\n",
    "X_val_tensor_conf = torch.tensor(X_val_conf).float()\n",
    "with torch.no_grad():\n",
    "    cnn_outputs = cnn_without_pca_conf(X_val_tensor_conf.unsqueeze(1))  # Add channel dimension\n",
    "    cnn_preds_enc = F.softmax(cnn_outputs, dim=1).argmax(dim=1)\n",
    "predicted_labels_cnn_no_pca_conf_val = [original_labels_conf[label] for label in cnn_preds_enc.numpy()]\n",
    "\n",
    "# Calculate validation metrics for confidence CNN without PCA\n",
    "ari_cnn_no_pca_conf_val = adjusted_rand_score(y_val_conf, predicted_labels_cnn_no_pca_conf_val)\n",
    "f1_cnn_no_pca_conf_val = f1_score(y_val_conf, predicted_labels_cnn_no_pca_conf_val, average='weighted')\n",
    "accuracy_cnn_no_pca_conf_val = accuracy_score(y_val_conf, predicted_labels_cnn_no_pca_conf_val)\n",
    "\n",
    "print(f\"Confidence CNN without PCA - Validation Accuracy: {accuracy_cnn_no_pca_conf_val:.3f}, ARI: {ari_cnn_no_pca_conf_val:.3f}, F1: {f1_cnn_no_pca_conf_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44358c34",
   "metadata": {},
   "source": [
    "## Confidence-weighted Validation Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82924c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation results summary for confidence-weighted pipeline\n",
    "print(\"=== CONFIDENCE-WEIGHTED VALIDATION RESULTS SUMMARY ===\")\n",
    "\n",
    "# Compile all confidence-weighted validation results\n",
    "confidence_validation_results = []\n",
    "\n",
    "# Add DNN results with PCA\n",
    "for i in range(len(dnn_list_conf)):\n",
    "    confidence_validation_results.append({\n",
    "        'model': f'conf_dnn_pca_{i+1}',\n",
    "        'architecture': 'DNN',\n",
    "        'pca_components': pca_dimensions_conf[i],\n",
    "        'training_accuracy': acc_list_conf[i],  # From training\n",
    "        'validation_accuracy': accuracy_list_dnn_conf_val[i],  # From validation\n",
    "        'validation_ari': ari_score_list_dnn_conf_val[i],\n",
    "        'validation_f1': f1_score_list_dnn_conf_val[i],\n",
    "        'confidence_weighted': True\n",
    "    })\n",
    "\n",
    "# Add DNN without PCA\n",
    "confidence_validation_results.append({\n",
    "    'model': 'conf_dnn_without_pca',\n",
    "    'architecture': 'DNN',\n",
    "    'pca_components': 'None',\n",
    "    'training_accuracy': acc_without_pca_conf,  # From training\n",
    "    'validation_accuracy': accuracy_dnn_no_pca_conf_val,  # From validation\n",
    "    'validation_ari': ari_dnn_no_pca_conf_val,\n",
    "    'validation_f1': f1_dnn_no_pca_conf_val,\n",
    "    'confidence_weighted': True\n",
    "})\n",
    "\n",
    "# Add CNN results with PCA\n",
    "for i in range(len(cnn_list_conf)):\n",
    "    confidence_validation_results.append({\n",
    "        'model': f'conf_cnn_pca_{i+1}',\n",
    "        'architecture': 'CNN',\n",
    "        'pca_components': pca_dimensions_conf[i],\n",
    "        'training_accuracy': acc_list_cnn_conf[i],  # From training\n",
    "        'validation_accuracy': accuracy_list_cnn_conf_val[i],  # From validation\n",
    "        'validation_ari': ari_score_list_cnn_conf_val[i],\n",
    "        'validation_f1': f1_score_list_cnn_conf_val[i],\n",
    "        'confidence_weighted': True\n",
    "    })\n",
    "\n",
    "# Add CNN without PCA\n",
    "confidence_validation_results.append({\n",
    "    'model': 'conf_cnn_without_pca',\n",
    "    'architecture': 'CNN',\n",
    "    'pca_components': 'None',\n",
    "    'training_accuracy': acc_without_pca_cnn_conf,  # From training\n",
    "    'validation_accuracy': accuracy_cnn_no_pca_conf_val,  # From validation\n",
    "    'validation_ari': ari_cnn_no_pca_conf_val,\n",
    "    'validation_f1': f1_cnn_no_pca_conf_val,\n",
    "    'confidence_weighted': True\n",
    "})\n",
    "\n",
    "# Create DataFrame and save results\n",
    "confidence_validation_results_df = pd.DataFrame(confidence_validation_results)\n",
    "confidence_validation_csv_path = f\"results/{result_subfolder_conf}/confidence_weighted_validation_results.csv\"\n",
    "\n",
    "# Create results directory for confidence models\n",
    "results_dir_conf = f\"results/{result_subfolder_conf}\"\n",
    "os.makedirs(results_dir_conf, exist_ok=True)\n",
    "\n",
    "confidence_validation_results_df.to_csv(confidence_validation_csv_path, index=False)\n",
    "\n",
    "print(f\"Confidence-weighted validation results saved to: {confidence_validation_csv_path}\")\n",
    "print(\"\\nConfidence-weighted Validation Results Summary:\")\n",
    "print(confidence_validation_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043db1c",
   "metadata": {},
   "source": [
    "# Final Test Set Evaluation - Confidence-weighted Models\n",
    "\n",
    "Final evaluation of confidence-weighted models on the test set for unbiased performance estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc815cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set for confidence-weighted DNN models\n",
    "print(\"=== FINAL TEST SET EVALUATION - CONFIDENCE-WEIGHTED DNN MODELS ===\")\n",
    "\n",
    "# Get original labels\n",
    "original_labels_conf = labelEncoder_conf.classes_.tolist()\n",
    "\n",
    "# Evaluate confidence DNN models with PCA on test set\n",
    "test_results_dnn_conf = []\n",
    "for i, dnn_model_conf in enumerate(dnn_list_conf):\n",
    "    X_test_tensor_conf = torch.tensor(X_test_pcaList_conf[i]).float()\n",
    "    with torch.no_grad():\n",
    "        dnn_outputs = dnn_model_conf(X_test_tensor_conf)\n",
    "        dnn_preds_enc = F.softmax(dnn_outputs, dim=1).argmax(dim=1)\n",
    "    \n",
    "    predicted_labels = [original_labels_conf[label] for label in dnn_preds_enc.numpy()]\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_ari = adjusted_rand_score(y_test_conf, predicted_labels)\n",
    "    test_f1 = f1_score(y_test_conf, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Calculate test accuracy manually\n",
    "    correct = (dnn_preds_enc.numpy() == y_test_conf).sum()\n",
    "    test_accuracy = correct / len(y_test_conf)\n",
    "    \n",
    "    test_results_dnn_conf.append({\n",
    "        'model': f'conf_dnn_pca_{i+1}',\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_ari': test_ari,\n",
    "        'test_f1': test_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Confidence DNN PCA {i+1} - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")\n",
    "\n",
    "# Evaluate confidence DNN without PCA on test set\n",
    "X_test_tensor_conf = torch.tensor(X_test_conf).float()\n",
    "with torch.no_grad():\n",
    "    dnn_outputs = dnn_without_pca_conf(X_test_tensor_conf)\n",
    "    dnn_preds_enc = F.softmax(dnn_outputs, dim=1).argmax(dim=1)\n",
    "\n",
    "predicted_labels = [original_labels_conf[label] for label in dnn_preds_enc.numpy()]\n",
    "test_ari = adjusted_rand_score(y_test_conf, predicted_labels)\n",
    "test_f1 = f1_score(y_test_conf, predicted_labels, average='weighted')\n",
    "correct = (dnn_preds_enc.numpy() == y_test_conf).sum()\n",
    "test_accuracy = correct / len(y_test_conf)\n",
    "\n",
    "test_results_dnn_conf.append({\n",
    "    'model': 'conf_dnn_without_pca',\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_ari': test_ari,\n",
    "    'test_f1': test_f1\n",
    "})\n",
    "\n",
    "print(f\"Confidence DNN without PCA - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be893dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set for confidence-weighted CNN models\n",
    "print(\"\\n=== FINAL TEST SET EVALUATION - CONFIDENCE-WEIGHTED CNN MODELS ===\")\n",
    "\n",
    "# Evaluate confidence CNN models with PCA on test set\n",
    "test_results_cnn_conf = []\n",
    "for i, cnn_model_conf in enumerate(cnn_list_conf):\n",
    "    X_test_tensor_conf = torch.tensor(X_test_pcaList_conf[i]).float()\n",
    "    with torch.no_grad():\n",
    "        cnn_outputs = cnn_model_conf(X_test_tensor_conf.unsqueeze(1))  # Add channel dimension for CNN\n",
    "        cnn_preds_enc = F.softmax(cnn_outputs, dim=1).argmax(dim=1)\n",
    "    \n",
    "    predicted_labels = [original_labels_conf[label] for label in cnn_preds_enc.numpy()]\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_ari = adjusted_rand_score(y_test_conf, predicted_labels)\n",
    "    test_f1 = f1_score(y_test_conf, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Calculate test accuracy manually\n",
    "    correct = (cnn_preds_enc.numpy() == y_test_conf).sum()\n",
    "    test_accuracy = correct / len(y_test_conf)\n",
    "    \n",
    "    test_results_cnn_conf.append({\n",
    "        'model': f'conf_cnn_pca_{i+1}',\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_ari': test_ari,\n",
    "        'test_f1': test_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Confidence CNN PCA {i+1} - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")\n",
    "\n",
    "# Evaluate confidence CNN without PCA on test set\n",
    "X_test_tensor_conf = torch.tensor(X_test_conf).float()\n",
    "with torch.no_grad():\n",
    "    cnn_outputs = cnn_without_pca_conf(X_test_tensor_conf.unsqueeze(1))  # Add channel dimension\n",
    "    cnn_preds_enc = F.softmax(cnn_outputs, dim=1).argmax(dim=1)\n",
    "\n",
    "predicted_labels = [original_labels_conf[label] for label in cnn_preds_enc.numpy()]\n",
    "test_ari = adjusted_rand_score(y_test_conf, predicted_labels)\n",
    "test_f1 = f1_score(y_test_conf, predicted_labels, average='weighted')\n",
    "correct = (cnn_preds_enc.numpy() == y_test_conf).sum()\n",
    "test_accuracy = correct / len(y_test_conf)\n",
    "\n",
    "test_results_cnn_conf.append({\n",
    "    'model': 'conf_cnn_without_pca',\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_ari': test_ari,\n",
    "    'test_f1': test_f1\n",
    "})\n",
    "\n",
    "print(f\"Confidence CNN without PCA - Test Accuracy: {test_accuracy:.3f}, ARI: {test_ari:.3f}, F1: {test_f1:.3f}\")\n",
    "\n",
    "# Save combined confidence test results\n",
    "print(\"\\n=== SAVING CONFIDENCE-WEIGHTED FINAL TEST RESULTS ===\")\n",
    "\n",
    "# Combine all confidence test results\n",
    "all_test_results_conf = test_results_dnn_conf + test_results_cnn_conf\n",
    "\n",
    "# Save to CSV\n",
    "test_results_conf_df = pd.DataFrame(all_test_results_conf)\n",
    "test_csv_path_conf = f\"results/{result_subfolder_conf}/final_test_scores_confidence_weighted.csv\"\n",
    "test_results_conf_df.to_csv(test_csv_path_conf, index=False)\n",
    "\n",
    "print(f\"Confidence-weighted final test results saved to: {test_csv_path_conf}\")\n",
    "print(\"\\nConfidence-weighted Final Test Results Summary:\")\n",
    "print(test_results_conf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c979b",
   "metadata": {},
   "source": [
    "## Visualize Confidence-weighted Model Predictions\n",
    "\n",
    "Let's visualize the predictions from confidence-weighted models and analyze the relationship between confidence scores and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f9bfe",
   "metadata": {},
   "source": [
    "## Visualize Main Pipeline Model Predictions\n",
    "\n",
    "Let's visualize the predictions from the main pipeline models for comparison with confidence-weighted models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc04f6",
   "metadata": {},
   "source": [
    "## Data Samples Used in Visualizations\n",
    "\n",
    "This section explains exactly which data samples are used in each visualization and how they are prepared.\n",
    "\n",
    "### **Visualization Overview**\n",
    "\n",
    "Your notebook contains **3 different visualizations** using different data samples:\n",
    "\n",
    "1. **Cell 17**: Basic sample points (all original data)\n",
    "2. **Cell 37**: Main pipeline predictions (validation subset only)  \n",
    "3. **Cell 39**: Confidence-weighted predictions (validation subset only)\n",
    "\n",
    "### **Data Sources and Sample Selection**\n",
    "\n",
    "#### **Cell 17: Basic Sample Visualization**\n",
    "- **Data Source**: `df` (original main pipeline dataset)\n",
    "- **File**: `\"training_data/WSI_patch_embeddings_centered-224_adenocarcinoma_leiden_0.3_training-data.csv\"`\n",
    "- **Samples Used**: **ALL samples** in the dataset\n",
    "- **Sample Count**: Full dataset (no filtering)\n",
    "- **What's Shown**: Red dots at all sample locations\n",
    "- **Purpose**: Overview of all sample positions on tissue\n",
    "\n",
    "#### **Cell 37: Main Pipeline Predictions Visualization**\n",
    "- **Data Source**: `df_predicted_main_val` (validation subset only)\n",
    "- **Original File**: Same as above (`\"training_data/WSI_patch_embeddings_centered-224_adenocarcinoma_leiden_0.3_training-data.csv\"`)\n",
    "- **Samples Used**: **VALIDATION SET ONLY** (20% of main dataset)\n",
    "- **Sample Selection Process**:\n",
    "  ```python\n",
    "  # Step 1: Split main dataset (60/20/20)\n",
    "  X_temp, X_test, y_temp, y_test = train_test_split(df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "  X_train_df, X_val_df, y_train_temp, y_val_temp = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "  \n",
    "  # Step 2: Use validation subset for visualization\n",
    "  df_predicted_main_val = X_val_df[['Patch_X', 'Patch_Y']].copy()\n",
    "  df_predicted_main_val['label'] = predicted_labels_dnn_no_pca  # Model predictions\n",
    "  ```\n",
    "- **What's Shown**: Colored patches showing DNN (no PCA) predictions for validation samples\n",
    "- **Purpose**: Visualize model predictions vs actual tissue structure\n",
    "\n",
    "#### **Cell 39: Confidence-weighted Predictions Visualization**\n",
    "- **Data Source**: `df_predicted_conf_val` (validation subset only)\n",
    "- **Original File**: `\"WSI_patch_embeddings_standard-224_adenocarcinoma_leiden_0.3_training-data_old.csv\"`\n",
    "- **Samples Used**: **VALIDATION SET ONLY** (20% of confidence dataset)\n",
    "- **Sample Selection Process**:\n",
    "  ```python\n",
    "  # Step 1: Split confidence dataset with index tracking (60/20/20)\n",
    "  indices = np.arange(len(X_conf))\n",
    "  X_temp_conf, X_test_conf, y_temp_conf, y_test_conf, idx_temp, idx_test = train_test_split(\n",
    "      X_conf, y_conf, indices, test_size=0.2, random_state=42, stratify=y_conf)\n",
    "  X_train_conf, X_val_conf, y_train_conf, y_val_conf, idx_train, idx_val = train_test_split(\n",
    "      X_temp_conf, y_temp_conf, idx_temp, test_size=0.25, random_state=42, stratify=y_temp_conf)\n",
    "  \n",
    "  # Step 2: Use preserved indices to map back to original dataframe\n",
    "  df_predicted_conf_val = df_conf.iloc[idx_val].copy()  # Use preserved validation indices\n",
    "  df_predicted_conf_val['label'] = predicted_labels_dnn_no_pca_conf_val  # Model predictions\n",
    "  df_predicted_conf_val['confidence'] = conf_val  # Confidence scores\n",
    "  ```\n",
    "- **What's Shown**: Colored patches showing confidence-weighted DNN (no PCA) predictions for validation samples\n",
    "- **Purpose**: Visualize confidence-weighted model predictions and analyze confidence patterns\n",
    "\n",
    "### **Key Differences Between Datasets**\n",
    "\n",
    "| Aspect | Main Pipeline (Cells 17, 37) | Confidence Pipeline (Cell 39) |\n",
    "|--------|-------------------------------|--------------------------------|\n",
    "| **Source File** | `WSI_patch_embeddings_centered-224_adenocarcinoma_leiden_0.3_training-data.csv` | `WSI_patch_embeddings_standard-224_adenocarcinoma_leiden_0.3_training-data_old.csv` |\n",
    "| **Processing** | Centered embeddings | Standard embeddings |\n",
    "| **Special Columns** | None | `confidence` column with scores |\n",
    "| **Visualization Samples** | Cell 17: All samples<br>Cell 37: Validation only | Cell 39: Validation only |\n",
    "| **Index Tracking** | Re-splits dataframe for visualization | Preserves original indices via `idx_val` |\n",
    "\n",
    "### **Sample Count Summary**\n",
    "\n",
    "The exact number of samples in each visualization depends on your dataset sizes, but the proportions are:\n",
    "\n",
    "- **Cell 17**: 100% of main dataset samples\n",
    "- **Cell 37**: ~20% of main dataset samples (validation set)\n",
    "- **Cell 39**: ~20% of confidence dataset samples (validation set)\n",
    "\n",
    "### **Why Only Validation Samples for Predictions?**\n",
    "\n",
    "The prediction visualizations (Cells 37 and 39) use only validation samples because:\n",
    "\n",
    "1. **Unbiased Evaluation**: Validation set wasn't used for training, so predictions are unbiased\n",
    "2. **Meaningful Comparison**: Both pipelines use the same 20% validation split methodology\n",
    "3. **Performance Assessment**: Shows how well models generalize to unseen data\n",
    "4. **Spatial Analysis**: Reveals if models learn spatial tissue patterns correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions from main pipeline DNN without PCA on validation set\n",
    "print(\"Visualizing main pipeline DNN predictions (without PCA) on validation set...\")\n",
    "\n",
    "# Create prediction dataframe for visualization using validation predictions\n",
    "# We need to map validation indices back to original dataframe\n",
    "X_temp, X_test_temp, y_temp, y_test_temp = train_test_split(df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train_df, X_val_df, y_train_temp, y_val_temp = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "df_predicted_main_val = X_val_df[['Patch_X', 'Patch_Y']].copy()\n",
    "df_predicted_main_val['label'] = predicted_labels_dnn_no_pca  # Main pipeline predictions\n",
    "\n",
    "# Visualize tissue with main pipeline predictions\n",
    "image_path = \"spatial/tissue_hires_image.png\"\n",
    "try:\n",
    "    visualize_tissue_image_with_samples_color_labels(image_path, df_predicted_main_val, 27482, 25219)\n",
    "    print(\"Main pipeline validation set visualization completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Main pipeline visualization error: {e}\")\n",
    "    print(\"Continuing with analysis...\")\n",
    "\n",
    "# Print some statistics about the main pipeline predictions\n",
    "print(f\"\\nMain Pipeline Validation Set Prediction Analysis:\")\n",
    "print(f\"Total validation samples: {len(df_predicted_main_val)}\")\n",
    "print(f\"Unique predicted labels: {df_predicted_main_val['label'].nunique()}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(df_predicted_main_val['label'].value_counts())\n",
    "\n",
    "# Show actual vs predicted label distribution\n",
    "actual_labels_main_val = [original_labels[label] for label in y_val]\n",
    "print(f\"\\nActual vs Predicted Label Distribution (Main Pipeline):\")\n",
    "print(f\"Actual labels distribution:\")\n",
    "unique_actual, counts_actual = np.unique(actual_labels_main_val, return_counts=True)\n",
    "for label, count in zip(unique_actual, counts_actual):\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "print(f\"Predicted labels distribution:\")\n",
    "predicted_counts = df_predicted_main_val['label'].value_counts()\n",
    "for label, count in predicted_counts.items():\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "# Calculate and show main pipeline validation accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "main_val_accuracy = accuracy_score(actual_labels_main_val, predicted_labels_dnn_no_pca)\n",
    "print(f\"\\nMain Pipeline DNN (no PCA) Validation Accuracy: {main_val_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ec66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Main Pipeline vs Confidence-weighted Predictions\n",
    "print(\"=== COMPARISON: MAIN PIPELINE vs CONFIDENCE-WEIGHTED PREDICTIONS ===\")\n",
    "\n",
    "# Compare prediction accuracy on validation sets\n",
    "print(f\"\\nValidation Set Performance Comparison:\")\n",
    "print(f\"Main Pipeline DNN (no PCA):\")\n",
    "print(f\"  - Accuracy: {accuracy_dnn_no_pca:.3f}\")\n",
    "print(f\"  - ARI: {ari_dnn_no_pca:.3f}\")\n",
    "print(f\"  - F1: {f1_dnn_no_pca:.3f}\")\n",
    "\n",
    "print(f\"\\nConfidence-weighted DNN (no PCA):\")\n",
    "print(f\"  - Accuracy: {accuracy_dnn_no_pca_conf_val:.3f}\")\n",
    "print(f\"  - ARI: {ari_dnn_no_pca_conf_val:.3f}\")\n",
    "print(f\"  - F1: {f1_dnn_no_pca_conf_val:.3f}\")\n",
    "\n",
    "# Calculate improvement/difference\n",
    "acc_diff = accuracy_dnn_no_pca_conf_val - accuracy_dnn_no_pca\n",
    "ari_diff = ari_dnn_no_pca_conf_val - ari_dnn_no_pca\n",
    "f1_diff = f1_dnn_no_pca_conf_val - f1_dnn_no_pca\n",
    "\n",
    "print(f\"\\nPerformance Difference (Confidence-weighted - Main):\")\n",
    "print(f\"  - Accuracy difference: {acc_diff:+.3f}\")\n",
    "print(f\"  - ARI difference: {ari_diff:+.3f}\")\n",
    "print(f\"  - F1 difference: {f1_diff:+.3f}\")\n",
    "\n",
    "if acc_diff > 0:\n",
    "    print(f\"\\n✓ Confidence weighting improves accuracy by {acc_diff:.3f}\")\n",
    "elif acc_diff < 0:\n",
    "    print(f\"\\n⚠ Confidence weighting decreases accuracy by {abs(acc_diff):.3f}\")\n",
    "else:\n",
    "    print(f\"\\n→ No accuracy difference between approaches\")\n",
    "\n",
    "# Show dataset information for comparison\n",
    "print(f\"\\nDataset Comparison:\")\n",
    "print(f\"Main Pipeline dataset: {df.shape[0]} samples\")\n",
    "print(f\"Confidence-weighted dataset: {df_conf.shape[0]} samples\")\n",
    "print(f\"Training epochs: {epochs} (main) vs {epochs_conf} (confidence)\")\n",
    "print(f\"PCA approach: Variance-based (main) vs Fixed components (confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions from confidence-weighted DNN without PCA on validation set\n",
    "print(\"Visualizing confidence-weighted DNN predictions (without PCA) on validation set...\")\n",
    "\n",
    "# Create prediction dataframe for visualization using validation predictions\n",
    "df_predicted_conf_val = df_conf.iloc[idx_val].copy()  # Use preserved validation indices\n",
    "df_predicted_conf_val = df_predicted_conf_val[['Patch_X', 'Patch_Y']].copy()\n",
    "df_predicted_conf_val['label'] = predicted_labels_dnn_no_pca_conf_val\n",
    "df_predicted_conf_val['confidence'] = conf_val  # Use validation confidence scores\n",
    "\n",
    "# Visualize tissue with confidence-weighted predictions\n",
    "image_path = \"spatial/tissue_hires_image.png\"\n",
    "try:\n",
    "    visualize_tissue_image_with_samples_color_labels(image_path, df_predicted_conf_val, 27482, 25219)\n",
    "    print(\"Validation set visualization completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "    print(\"Continuing with analysis...\")\n",
    "\n",
    "# Print some statistics about the predictions vs confidence\n",
    "print(f\"\\nValidation Set Prediction-Confidence Analysis:\")\n",
    "print(f\"Total validation samples: {len(df_predicted_conf_val)}\")\n",
    "print(f\"Unique predicted labels: {df_predicted_conf_val['label'].nunique()}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(df_predicted_conf_val['label'].value_counts())\n",
    "\n",
    "# Show confidence distribution by predicted label\n",
    "print(f\"\\nConfidence by predicted label (validation set):\")\n",
    "confidence_by_label_val = df_predicted_conf_val.groupby('label')['confidence'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(confidence_by_label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0144a",
   "metadata": {},
   "source": [
    "## Confidence-weighted Results Summary and Comparison\n",
    "\n",
    "This section provides a comprehensive summary of all confidence-weighted model results and compares them with the main pipeline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confidence-weighted pipeline summary\n",
    "print(\"=== CONFIDENCE-WEIGHTED PIPELINE SUMMARY ===\")\n",
    "\n",
    "print(f\"\\nConfidence statistics:\")\n",
    "print(f\"- Mean confidence: {confidence_scores.mean():.3f}\")\n",
    "print(f\"- Confidence range: {confidence_scores.min():.3f} - {confidence_scores.max():.3f}\")\n",
    "print(f\"- Dataset split: {X_train_conf.shape[0]} train / {X_val_conf.shape[0]} val / {X_test_conf.shape[0]} test\")\n",
    "print(f\"- All models use confidence-weighted loss during training\")\n",
    "\n",
    "print(f\"\\nModel architectures trained:\")\n",
    "print(f\"- DNN models with PCA: {len(dnn_list_conf)}\")\n",
    "print(f\"- DNN without PCA: 1\")\n",
    "print(f\"- CNN models with PCA: {len(cnn_list_conf)}\")\n",
    "print(f\"- CNN without PCA: 1\")\n",
    "print(f\"- Total confidence-weighted models: {len(dnn_list_conf) + 1 + len(cnn_list_conf) + 1}\")\n",
    "\n",
    "print(f\"\\nResults saved to:\")\n",
    "print(f\"- Validation results: results/{result_subfolder_conf}/confidence_weighted_validation_results.csv\")\n",
    "print(f\"- Test results: results/{result_subfolder_conf}/final_test_scores_confidence_weighted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c98bfe0",
   "metadata": {},
   "source": [
    "## Visualize Confidence-weighted Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization options and analysis can be added here\n",
    "print(\"=== ADDITIONAL ANALYSIS OPPORTUNITIES ===\")\n",
    "print(\"1. Compare main pipeline vs confidence-weighted pipeline performance\")\n",
    "print(\"2. Analyze which samples benefit most from confidence weighting\")\n",
    "print(\"3. Study correlation between confidence scores and prediction accuracy\")\n",
    "print(\"4. Visualize confidence distribution across tissue regions\")\n",
    "print(\"5. Compare validation vs test performance for overfitting detection\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfolab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
